\section{Diskussion}

\subsection{Welche Ziele wurden erreicht?}
In diesem Abschnitt wird der Abgleich der ursprünglich definierten Projektziele (siehe Abschnitt 1.2) mit den tatsächlich erzielten Ergebnissen (dargestellt in Abschnitt 5) vorgenommen.

\begin{itemize}
    \item \textbf{Primärziel - Hands-On Tutorial:} Es wurde erfolgreich ein praxisorientiertes Hands-On-Tutorial für die THU Summer School entwickelt. Der Kern des Tutorials liegt in der kostengünstigen Umsetzung von Methoden zur Personen- und Schrifterkennung mittels eines Raspberry Pi. Es demonstriert Computer-Vision-Technologien, primär auf Basis von YOLOv5.
    \begin{itemize}
        \item \textbf{Kennzeichenerkennung (OCR):} Das entwickelte System ist in der Lage, Kfz-Kennzeichen aus Bilddateien zu detektieren und deren alphanumerischen Inhalt auszulesen. Eine Optimierung erfolgte spezifisch für deutsche Kennzeichenformate. Die durchgeführten Testläufe illustrierten sowohl die grundsätzliche Funktionsfähigkeit als auch die typischen Fehlerquellen unter Laborbedingungen.
        \item \textbf{Personenerkennung (Gesichter):} Es wurde eine KI-gestützte Personenerkennung implementiert, die das Erlernen, Unterscheiden und Wiedererkennen von Gesichtern ermöglicht. Das Tutorial vermittelt den Studierenden den Umgang mit den Modellen YOLO und MediaPipe für diese Aufgabe.
    \end{itemize}
    \item \textbf{Sekundärziel - Anwendungsszenarien:} Die beiden Erkennungsaufgaben dienen als praxisnahe Demonstrationen für potenzielle Anwendungsfälle, wie automatisierte Mautprozesse oder Zutrittskontrollsysteme. Ziel war es hierbei, ein grundlegendes Verständnis für die technische Realisierung und die damit verbundenen Herausforderungen zu schaffen.
    \item \textbf{Technische Umsetzung und Plattform:} Das Tutorial wurde erfolgreich auf einem Raspberry Pi implementiert. Dies bestätigt die Machbarkeit der vorgestellten Methoden auf ressourcenbeschränkter Hardware und gibt Einblicke in das Feld des \textit{Tiny Machine Learning}.
    \item \textbf{Evaluation und Lehrmaterial:} Erste Testläufe mit Studierenden lieferten wertvolles Feedback. Basierend darauf wurde das Lehrmaterial in Form einer PowerPoint-Präsentation aufbereitet und um eine optionale Zusatzaufgabe zur Vertiefung der Kennzeichenerkennung ergänzt.
\end{itemize}

\subsection{Retrospektive}

\subsubsection{Was lief gut?}
Zusätzlich zu den bereits etablierten positiven Aspekten der Teamarbeit und Dokumentation können folgende Punkte hervorgehoben werden:
\begin{itemize}
    \item Die Kommunikation im Team war durchweg konstruktiv und effizient.
    \item Die vereinbarte Arbeitsteilung funktionierte gut und wurde konsequent eingehalten.
    \item Die Projektdokumentation ist umfassend und klar strukturiert.
    \item Der entwickelte Code ist gut organisiert und ausreichend kommentiert.
    \item \textbf{Testläufe und Feedback:} Studierende mit technischem Hintergrund konnten das Tutorial erfolgreich bearbeiten. Das bereitgestellte Installationsskript wurde als große Hilfe bei der Einrichtung des Raspberry Pi empfunden. Die Aufbereitung der Lehrmaterialien als PowerPoint-Präsentation fand Anklang.
    \item \textbf{Gesichtserkennung (YOLO):} Die Kombination aus YOLOv8n-face und dem \texttt{face\_recognition}-Framework ermöglichte eine zuverlässige Gesichtserkennung (ca. 93\% in Tests).
    \item \textbf{Gesichtserkennung (MediaPipe):} Die Gesichtspunkterkennung mittels MediaPipe Face Mesh erwies sich als präzise und echtzeitfähig. Das darauf aufbauende Wiedererkennungssystem zeigte trotz bekannter Limitationen eine für viele Anwendungsfälle ausreichende Performance (ca. 23 FPS im Test).
\end{itemize}  

\subsubsection{Was lief nicht so gut?}
Neben den Erfolgen traten auch Herausforderungen und Limitationen auf, die hier reflektiert werden:
\begin{itemize}
    \item \textbf{Kennzeichenerkennung - Universalität:} Die enorme globale Vielfalt an Kennzeichenformaten und Schriftarten verhinderte die Entwicklung einer universell einsetzbaren Lösung im Rahmen des Projekts. Der Fokus musste daher auf deutsche Kennzeichen gelegt werden.
    \item \textbf{Kennzeichenerkennung - Robustheit unter Realbedingungen:} Die Anpassung des Systems an stark variierende Lichtverhältnisse (Schatten, Überbelichtung) sowie an Verschmutzungen auf den Kennzeichen erwies sich als komplex. Eine robuste Lösung für alle denkbaren Umgebungsbedingungen hätte den Projektrahmen gesprengt.
    \item \textbf{Kennzeichenerkennung - OCR-Genauigkeit:} Die verwendete OCR-Engine (Tesseract) zeigte Schwächen bei der Unterscheidung ähnlicher Zeichen wie '0', 'G' und 'O', was zu Fehlern bei der Textextraktion führte.
    \item \textbf{Hardwarelimitierungen des Raspberry Pi:} Insbesondere die OCR-Komponente zur Schriftzeichenerkennung stellte hohe Anforderungen an die Rechenleistung des Raspberry Pi, was die Echtzeitfähigkeit des Gesamtsystems einschränkte. Der Einsatz von EasyOCR scheiterte an dessen hohem Speicherbedarf und den langen Inferenzzeiten auf der Zielhardware.
    \item \textbf{Gesichtserkennung (MediaPipe - Wiedererkennung):} MediaPipe allein ist für robuste biometrische Identifikationsaufgaben, wie sie bei Zutrittskontrollen benötigt werden, nur eingeschränkt tauglich. Die verwendete Landmarken-Distanz-Methode ist anfällig für Variationen in Mimik, Kopfhaltung und Beleuchtung. Zudem fehlt eine integrierte Lebenderkennung (\textit{Liveness Detection}), um Täuschungsversuche (z.B. durch Vorhalten eines Fotos) abzuwehren.
    \item \textbf{Tutorial-Schwierigkeitsgrad:} Ein Testlauf mit einem Studierenden ohne spezifischen technischen Hintergrund zeigte, dass das Tutorial für diese Zielgruppe potenziell eine hohe Einstiegshürde darstellt und die Bearbeitung innerhalb der vorgesehenen Zeit schwierig sein kann.
\end{itemize}


\subsubsection{Lessons Learned}

 \paragraph{Valentin Talmon-l'Armée:} 
 Im Verlauf des Projekts habe ich wertvolle Einblicke in die praktische Anwendung von KI-Verfahren und die Bildverarbeitung gewonnen. Besonders das Arbeiten mit dem Raspberry Pi und die Nutzung von Git zur Versionskontrolle haben mein technisches Verständnis erweitert. Ich habe gelernt, dass neben der technischen Umsetzung auch eine klare und regelmäßige Abstimmung im Team entscheidend für den Projekterfolg ist. Die iterative Auseinandersetzung mit OCR- und Detektionsmethoden hat mir gezeigt, wie wichtig systematisches Testen und Anpassen im Entwicklungsprozess ist. Insgesamt konnte ich mein Wissen in mehreren Bereichen gezielt vertiefen und besser miteinander verknüpfen.

\paragraph{Jan Gaschler:}
Das Projekt hat mir nicht nur technische Fähigkeiten vermittelt, sondern auch meine Teamarbeit und Kommunikationsfähigkeiten gestärkt. Die enge Zusammenarbeit mit meinen Kommilitonen war entscheidend für den Erfolg des Projekts. Ich habe gelernt, wie wichtig es ist, Feedback zu geben und zu empfangen, um gemeinsam Lösungen zu finden. Besonders die Herausforderungen bei der Implementierung der Gesichtserkennung haben mir gezeigt, wie wichtig es ist, flexibel zu bleiben und alternative Ansätze in Betracht zu ziehen. Ich habe auch ein besseres Verständnis für die ethischen Implikationen von Gesichtserkennungstechnologien entwickelt und werde diese Überlegungen in zukünftige Projekte einfließen lassen.